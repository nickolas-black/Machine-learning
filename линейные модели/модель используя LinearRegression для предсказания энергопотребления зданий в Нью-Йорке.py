# -*- coding: utf-8 -*-
"""ДЗ_№4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A8MWqLICtE69dwbMF9kcOQs_QUtQnI3J

##Датасет взят с сайта: https://www1.nyc.gov/html/gbee/html/plan/ll84_scores.shtml

## построить модель используя LinearRegression для предсказания энергопотребления зданий в Нью-Йорке;

использовать иснтруметы нормализации/стандартизации признаков;

использовать по крайней мере один из способов отбора признаков (см. блокнот с вебинара).

##построить модель используя LinearRegression, LinearSVR для предсказания энергопотребления зданий в Нью-Йорке;

произвести нормализацию признаков в случае необходимости;

использовать все инструменты для отбора признаков;
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from google.colab import files
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.stats import kurtosis
from scipy.stats import skew
from scipy.stats import shapiro
from scipy.stats import normaltest
from IPython.core.pylabtools import figsize
import seaborn as sns
from sklearn.model_selection import train_test_split
from IPython.core.pylabtools import figsize
from sklearn.preprocessing import PowerTransformer
from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV
from sklearn.svm import LinearSVR
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
from sklearn.metrics import mean_absolute_error
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""## Создал функцию для удобства просмотра"""

## Просмотр данных
def prosmotr(data):
  pd.set_option('display.max_columns', 100) #Размеры таблицы
  pd.set_option('display.max_rows', 100)
  pd.set_option('precision', 2) #Регулируем количество знаков после запятой:
  print('~~~~Содержание данных~~~~\n', data.head())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Размеры данных~~~\n', data.shape)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Названия колонок~~~\n', data.columns)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Информация о данных~~~\n')
  print(data.info())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Наличие пропусков в данных~~~\n', data.isna().sum())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Количество типов в данных~~~')
  print(data.dtypes.value_counts())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  kateg = list(data.select_dtypes(include=['object']).columns) # Делаем список категориальных данных
  print('~~~Категориальные данные~~~~')
  print(kateg)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_float = list(data.select_dtypes(include=['float64'])) #Делаем список числовых данных float
  print('~~~Числове данные float~~~~')
  print(chislov_float)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_int = list(data.select_dtypes(include=['int64'])) #Делаем список числовых данных int
  print('~~~Числове данные int~~~~')
  print(chislov_int)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы int64)~~~\n', data.describe(include=['int64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы float64)~~~\n', data.describe(include=['float64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Cтатистика по нечисловым признакам object ~~~\n', data.describe(include=['object']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
#  print('~~~Cтатистика по нечисловым признакам bool ~~~\n', data.describe(include=['bool'])) этих данных просто нет в наборе данных
#  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')

## Анализ данных
def analyze(data):
  num = data.columns
  for i in num:
    print(i.title())
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')
    print("mean : ", np.mean(data[i]))
    print("var  : ", np.var(data[i]))
    print("skew : ", skew(data[i]))
    print("kurt : ", kurtosis(data[i]))
    print("shapiro : ", shapiro(data[i]))
    print("normaltest : ", normaltest(data[i]))
    print('~~~~~~~~~~~~~~~~~~~~~~~~~')
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')

"""## Функции для работы с данными"""

## функция для просмотра пропусков в данных

def values_table_null(data):
        # всего пропусков
        mis_val = data.isnull().sum()
        
        # процент пропусков
        mis_val_percent = 100 * data.isnull().sum() / len(data)
        
        # Делаем таблицу с получившимися результатами
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        
        # Переименовать столбцы
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : 'Missing Values', 1 : '% of Total Values'})
        
        # Сортировка таблицы по проценту пропущенных по убыванию
        mis_val_table_ren_columns = mis_val_table_ren_columns[
            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        '% of Total Values', ascending=False).round(1)
        
        # Выввод на печать сводную информацию
        print ("Выбранныей Вами данные " + str(data.shape[1]) + " колонок.\n"      
            "Из них " + str(mis_val_table_ren_columns.shape[0]) +
              " имеют пропуск")      

        return mis_val_table_ren_columns

"""## Функции по алгоритмам"""

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV


def fit_model(model, X, y, parameters):  
  cross_validation = StratifiedKFold(n_splits=5)

  grid_search = GridSearchCV(model,
                              scoring='accuracy',
                              param_grid=parameters,
                              cv=cross_validation,
                              verbose=1
                            )

  grid_search.fit(X, y)
  parameters=grid_search.best_params_
  print('Best score: {}'.format(grid_search.best_score_))
  print('Best parameters: {}'.format(parameters))

  return grid_search

"""### Чтение из файла и первичный анализ"""

df= pd.read_csv('/content/drive/My Drive/dataset/energy/Energy_and_Water_Data_Disclosure_for_Local_Law_84_2017__Data_for_Calendar_Year_2016_.csv')

prosmotr(df)

df.head(3)

"""## Нашел описание каждого признака
http://www.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_definitions_2017.pdf

## Order	
  Заказ BBL на раскрытие данных
## Property Id
  Номер, присвоенный каждому представлению бенчмаркинга портфельный
	менеджер. Это значение является уникальным для каждой записи,
	представленной в поле BBL. Обратите внимание, что если бы не было никакого
	представления бенчмаркинг получили Департамент финансов, то нет назначена	
	запись номера в столбце.
	
## Property Name	
  Основная информация о недвижимости включает в себя имя свойства.

## Parent Property Id
  Идентификатор для кампуса упоминается как родитель ID недвижимости
	
## Parent Property Name
	Когда вы тест кампус (или набор зданий) вы можете отслеживать
	информацию по всей территории кампуса, а также для отдельных
	зданий на территории кампуса. Если вы хотите отслеживать на обоих
	этих уровнях, то есть «родитель-потомок». «Родитель» является всем
	кампусом или сложным. То есть, родитель мульти-здание	собственность,
  для которого вы также выбрали для тестов отдельных
	зданий отдельно.
	
## BBL - 10 digits
  10-значное свойство р-н, блок и идентификатор много, первоначально
	введенная в поле «Стандартные идентификаторы» в Portfolio Manager, а
	затем проверяется и корректируется, по мере необходимости, Департамент
	финансов (DOF). Первое число представляет собой р-н, где 1 Manhattan, 2
	Бронкс, Бруклин 3, 4 Квинс, и 5 Статен-Айленд. Следующие пяти цифр
	представляют налоговый блок. Если свойство имеет налоговый блок,
	который меньше, чем 5 цифр, то нули добавляются перед номером блока,
	так что пяти цифр в целом. Последние четыре цифры являются номером
	налога много.
  
## NYC Borough, Block and Lot (BBL) self-	
	10-значное свойство р-н, блок и идентификатор много, selfreported

## NYC Building Identification Number (BIN))		
  Самоотчеты семизначный идентификационный номер здания.
					
## Address 1 (self-reported)		
  Улица 1 (самооценка)	
  
## Address 2	
  Улица 2 (самооценка)	
  
## Postal Code
  Почтовый индекс для недвижимости, сообщает самостоятельно
				
## Street Number
  Номер дома на имущество, за DOF записей.

## Street Name
  Название улицы за собственность, за DOF записей.

## Borough
  Местечко на имущество, за DOF записей.			

## DOF Gross Floor Area
  Брутто площадь участка имущества, за DOF записей.

## Primary Property Type - Self Selected	
  Самоотчеты варианта типа недвижимости, доступная в диспетчере Portfolio.
  
## List of All Property Use Types at Property	
  Разделенный запятыми список всех типов свойств для одного
		свойства, в алфавитном порядке.			
					
## Largest Property Use Type
  Название Тип собственности (например: Office), который имеет самую большую
		площадь брутто (GFA) для этого свойства.			
										
## Largest Property Use Type - Gross Floor Area (ft²)
  GFA для крупнейшего Тип недвижимости.			

## 2nd Largest Property Use Type
  Название Тип собственности (например: Office), который имеет второй по
		величине GFA для этого свойства.			
										
## 2nd Largest Property Use - Gross Floor Area (ft²)
  GFA для второго по величине Типа недвижимости.			

## 3rd Largest Property Use Type		
  Название Тип собственности (например: Office), который имеет третий по
		величине GFA для этого свойства.			
					
## 3rd Largest Property Use Type - Gross Floor Area (ft²)	
  GFA для третьего по величине Типа недвижимости.			

## Year Built
		Это год, в котором была построена ваша собственность. Если ваша
		собственность подверглась полной реконструкции, которая включала
		потрошения и восстановление интерьера, то вы можете указать дату
		этого обновления в год построен. Если вы не знаете точный год свойство
		было построено, введите оценку.			
				
## Number of Buildings - Self-reported
  Количество зданий показывает общее количество зданий, которые
		расположены на налоговый жребию.			
				
## Occupancy
  Процент Gross площадь вашего имущества (GFA),
		занимаемый и работоспособны.			
					
## Metered Areas (Energy)	
  Измеренный Areas этого обозначения того, что районы в пределах вашего
		здания покрыты ваши энергии и счетчики воды.			
					
## Metered Areas (Water)
  Измеренный Areas этого обозначения того, что районы в пределах вашего
		здания покрыты ваши энергии и счетчики воды.			

## ENERGY STAR Score
		1-к-100 процентиля ранжирования для определенных типов зданий,
		рассчитанных в Portfolio Manager, на основе самооценки потребления
		энергии за отчетный год.	
    
## Site EUI (kBtu/ft²)
		Интенсивность использования энергии, что рассчитывается менеджером
		портфеля на сайте недвижимости в kBtus на валовой квадратный фут (КБТУ /
		ft2), за отчетный год.			
				
## Weather Normalized Site EUI (kBtu/ft²)	
  Интенсивность использования энергии, что рассчитывается по Portfolio Manager
		на сайте недвижимости в kBtus за квадратный фут брутто
## ENERGY STAR Score		
  (КБТ / ft2) за отчетный год, нормализует погоды.

## Weather Normalized Site Electricity	Intensity (kWh/ft²)
  Погода Нормированная сайта Энергия делится на размер имущества	
	или с помощью потока через станцию очистки воды / сточных вод.
		
## Weather Normalized Site Natural Gas Intensity (therms/ft²)		
  Погода Нормированная сайта Энергия делится на размер имущества	
		или с помощью потока через станцию очистки воды / сточных вод.

## Weather Normalized Source EUI (kBtu/ft²)					
		Энергоемкость использование, рассчитанный Portfolio Manager на	
		источнике генерации энергии в kBtus на валовой квадратный фут (КБТ /	
		ft2) за отчетный год, нормализуют погоды.	
			
## Fuel Oil #1 Use (kBtu)					
		Использование энергии по типу представляет собой резюме ежегодного	
	потребления отдельного вида энергии. Годовые итоговые данные доступны	
		для топочного мазута № 1.	
## Fuel Oil #2 Use (kBtu)				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые итоговые данные доступны	
		для топочного мазута № 2.	
## Fuel Oil #4 Use (kBtu)				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые итоговые данные доступны	
		для топочного мазута № 4.	
## Fuel Oil #5 & 6 Use (kBtu))				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые итоговые данные доступны	
		для мазутного № 5 и 6.	
## Diesel #2 Use (kBtu)				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые суммы доступны для	
		дизельного топлива # 2.	
## District Steam Use (kBtu))				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые итоговые данные доступны	
		для района Steam.	
## Natural Gas Use (kBtu)				
		Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые суммы доступны для	
		природного газа.	
				
## Weather Normalized Site Natural Gas Use	(therms)	
    Энергия использовать свойство потребляла бы в течение	
		30-летнего среднего погодных условий	
## Electricity Use - Grid Purchase (kBtu)
    Использование энергии по типу представляет собой резюме ежегодного	
		потребления отдельного вида энергии. Годовые суммы доступны для	
		использования электроэнергии - Сетка Purchase.	
				
## Weather Normalized Site Electricity (kWh)		
    Энергия использовать свойство потребляла бы в течение	
		30-летнего среднего погодных условий	
## Total GHG Emissions (Metric Tons CO2e)			
		Суммарные прямые и косвенные парниковые газы, испускаемые	
		собственностиCO2e)	, сообщили в метрических тоннах эквивалента двуокиси	
		углерода (MtCO2e) за отчетный год.
## Direct GHG Emissions (Metric Tons CO2e)    
		Суммарные прямые парниковые газы, испускаемые собственности,	
		сообщили в метрических тоннах эквивалента двуокиси углерода	
		(MtCO2e) за отчетный год.	
## Indirect GHG Emissions (Metric Tons CO2e)    
		Суммарные косвенные парниковые газы, испускаемые собственности,	
		сообщили в метрических тоннах эквивалента двуокиси углерода	
		(MtCO2e) за отчетный год.	
## Property GFA - Self-Reported (ft²)	
    Самоотчетам Совокупная площадь участка (ft2) имущества.				
		
## Water Use (All Water Sources) (kgal)	
    Сумма всех счетчиков воды.	

## Water Intensity (All Water Sources)	(gal/ft²)		
    N / A	
## Source EUI (kBtu/ft²)		
	Интенсивность использования энергии, что рассчитывается портфельный	
	менеджер источника генерации энергии в kBtus на валовой квадратный фут	
	(КБТУ / ft2), за отчетный год.		
		
## Release Date	
  Дата представления был выпущен через портфель Сити	
	Управление шаблон.		
## Water Required?			
	Указывает, что свойство имел право использовать данные	
	бенчмаркинга воды, загруженные Департаментом охраны	
	окружающей среды.		
## Zip Code	
  Почтовый индекс для имущества, за DOF записей.

## Посмотрим пропуски
"""

values_table_null(df)

df.head()

"""## Так как довольно часто встречается "Not Available" в числовых признаках. Заменив записи "Not Available" на np.nan, который можно интерпретировать как число с плавающей точкой. Затем мы преобразуем столбцы, которые содержат числовые значения (например, квадратные футы или потребление энергии) в числовые типы данных"""

df = df.replace({'Not Available': np.nan})

for col in list(df.columns):
    
    if ('ft²' in col or 'kBtu' in col or 'Metric Tons CO2e' in col or 'kWh' in 
        col or 'therms' in col or 'gal' in col or 'Score' in col):
       
        df[col] = df[col].astype(float)

## Посмотрим статистику получившуюся
df.describe()

## Проверим еще раз на пропуски
values_table_null(df)

"""## Видно что есть параметры которые практически полность пустые и мало вероятно, что они несут какую-то смысловую нагрузку, поэтому удали все столбцы которые больше 50 %"""

missing_df = values_table_null(df);
missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)
print('Удаляем %d колонок.' % len(missing_columns))

df = df.drop(columns = list(missing_columns))
df.head(3)

# Избавимся от ненужных признаков
df.drop(['NYC Building Identification Number (BIN)'], axis=1, inplace=True)
df.drop(df[df['Community Board']==56].index, inplace=True)
df.drop(['Property Name', 'Parent Property Name', 'Postal Code', 'NTA'], axis=1, inplace=True) 
df.drop(['Release Date', 'Council District', 'BBL - 10 digits'], axis=1, inplace=True) 
df.drop(['Parent Property Id', 'Property Id', 'Order'], axis=1, inplace=True) 
df.drop(['NYC Borough, Block and Lot (BBL) self-reported', 'Census Tract'], axis=1, inplace=True)	
df.drop(['Street Name'], axis=1, inplace=True) 
df.drop(['Street Number', 'Address 1 (self-reported)'], axis=1, inplace=True) 
df.drop(['List of All Property Use Types at Property'], axis=1, inplace=True) 
df.drop(['Number of Buildings - Self-reported'], axis=1, inplace=True) 
df.drop(['Metered Areas (Energy)'], axis=1, inplace=True) 
df.drop(df[df['ENERGY STAR Score'].isnull()].index, inplace=True)

# Заполняем пустые значения
df[(df['Metered Areas  (Water)']!='Whole Building') & (df['Metered Areas  (Water)'].isnull())] = 0 
df['Community Board'][df['Community Board'].isnull()] = 0 

df['Community Board'] = df['Community Board'].astype('int32')

float_cols = list(df.select_dtypes('float64').columns) + ['Occupancy']

for col in float_cols:
  df[col].fillna(df[col].mean(), inplace=True) #----------------------------------------------------- Заменяем пустые значения средним
  
df['Borough'].fillna(0, inplace=True) #-------------------------------------------------------------- Заполним самым частым значением
df['Water Required?'].fillna('Yes', inplace=True) #-------------------------------------------------- Аналогично предыдущему 
df['Water Required?'].fillna('Yes', inplace=True) #-------------------------------------------------- Аналогично предыдущему 
df['DOF Benchmarking Submission Status'].fillna('In Compliance', inplace=True) #--------------------- Аналогично предыдущему

# Работа с категориальными признаками
df['Year Built'] = df['Year Built'].apply(lambda x: 'uknown year' if x==0 else 'known year')
categorical_cols = ['Borough', 'Primary Property Type - Self Selected', 'Largest Property Use Type', 'Metered Areas  (Water)', 'Water Required?', 'DOF Benchmarking Submission Status', 'Community Board', 'Year Built']
dummies = pd.get_dummies(df[categorical_cols])
df.drop(categorical_cols, axis=1, inplace = True)
df = pd.concat([df, dummies], axis=1)

# Нормировка, нормализация и стандартизация
for col in float_cols:
  df[col] = df[col].apply(lambda x: x/df[col].mean())
  
yeo = PowerTransformer(method='yeo-johnson', standardize=False)
for col in float_cols:
    df[col] = yeo.fit_transform(df[col].values.reshape(df.shape[0],-1))
    
scaler = StandardScaler()
scaler.fit(df[float_cols])
df[float_cols] = scaler.transform(df[float_cols])

"""## Строим зависимости"""

corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize(20, 10))
plt.xticks(rotation=90)
plt.bar(top_corr_features, height=list(df[top_corr_features].corr()['ENERGY STAR Score']))

features_dict = df[top_corr_features].corr()['ENERGY STAR Score'].to_dict()
best_features = [i for i,j in zip(features_dict.keys(), features_dict.values()) if j > 0.5]

df_with_best_features = df[best_features].corr()
plt.figure(figsize=(20,20))
g=sns.heatmap(df_with_best_features,annot=True,cmap="RdYlGn")

"""## Top признаков"""

df_with_best_features.max()

df = df[best_features]

analyze(df)

"""# Выделим основную цель и уберем из тренировочного набора"""

y = df['ENERGY STAR Score']
df = df.drop(['ENERGY STAR Score'],axis=1)

X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""# Алгоритмы

## LR
"""

# создаем параметры LR для перебора в GridSearchCV
parameters_LR = [{'fit_intercept': ['True', 'False']}]

# создаем модель на основее LinearRegression и с помощью GridSearchCV
# подбираем оптимальные параметры и обучаем
LR_FS = GridSearchCV(LinearRegression(), parameters_LR, cv=5)
LR_FS.fit(X_train,y_train)
LR_FS.best_params_

"""## MAE"""

np.round(LR_FS.score(X_test,y_test), 2)

y_pred = LR_FS.predict(X_test)

mae = np.mean(abs(y_pred - y_test))
print('LR: MAE = %0.4f' % mae)

"""## Scores"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

fold = KFold(n_splits=5, shuffle=True, random_state=5)
scores = cross_val_score(estimator = LR_FS, X=X_train, y=y_train,cv=fold)
print('Общее ', scores)
print('Сроеднее ', scores.mean())
print('Минимальное ',scores.min())
print('Максимальное ', scores.max())

"""## LSVR"""

# создаем параметры LSVR для перебора в GridSearchCV
parameters_LSVR = [{'epsilon': [0, 0.05, 0.1, 0.5, 1, 4] , 
                          'loss': ['epsilon_insensitive','squared_epsilon_insensitive'], 
                          'fit_intercept': ['True', 'False']}]

# создаем модель на основее LinearSVR и с помощью GridSearchCV
# подбираем оптимальные параметры и обучаем
LSVR = GridSearchCV(LinearSVR(), parameters_LSVR, cv=5)
LSVR.fit(X_train,y_train)
LSVR.best_params_

"""## MAE"""

np.round(LSVR.score(X_test,y_test), 2)

y_pred_LSVR = LSVR.predict(X_test)

mae = np.mean(abs(y_pred_LSVR - y_test))
print('LSVR: MAE = %0.4f' % mae)

"""## Scores"""

fold = KFold(n_splits=5, shuffle=True, random_state=5)
scores = cross_val_score(estimator = LSVR, X=X_train, y=y_train,cv=fold)
print('Общее ', scores)
print('Сроеднее ', scores.mean())
print('Минимальное ',scores.min())
print('Максимальное ', scores.max())