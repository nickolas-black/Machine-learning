{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NLP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPr1aiiT2BUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3hJHGvK2BUe",
        "colab_type": "text"
      },
      "source": [
        "Simple tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32YE5_tA2BUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mytweet = \"@john lol that was #awesome :)\"\n",
        "nltk.word_tokenize(mytweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oofmB-IW2BUk",
        "colab_type": "text"
      },
      "source": [
        "Special tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1kgkqQJ2BUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cNFrz4b2BUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TweetTokenizer()\n",
        "tokenizer.tokenize(mytweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5OGLn4S2BUv",
        "colab_type": "text"
      },
      "source": [
        "Multi-Word Expression Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1o9EjAs2BUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import MWETokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpI3tt5K2BU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = MWETokenizer([('a', 'little'), ('a', 'little', 'bit'), ('a', 'lot')])\n",
        "tokenizer.add_mwe(('in', 'spite', 'of'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZFt_JVQ2BU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize('Testing testing testing one two three'.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zED03IjW2BU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize('This is a test in spite of'.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB52QoNN2BVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize('In a little or a little bit or a lot in spite of'.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09velHH2BVF",
        "colab_type": "text"
      },
      "source": [
        "Regular-Expression Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0jnxZd2BVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "s = \"Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\n\\nThanks.\"\n",
        "tokenizer = RegexpTokenizer('\\w+')#'\\w+|\\$[\\d\\.]+|\\S+'\n",
        "tokenizer.tokenize(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Kv6jnS2BVL",
        "colab_type": "text"
      },
      "source": [
        "Stemmers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAhn9f4m2BVM",
        "colab_type": "code",
        "colab": {},
        "outputId": "98e02b5e-cfd7-4b75-9b33-ddd026b72f7d"
      },
      "source": [
        "import nltk\n",
        "ps = nltk.stem.PorterStemmer()\n",
        "print(ps.stem('grows'),ps.stem('leaves'),ps.stem('fairly'),ps.stem('provision'),ps.stem('owed') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grow leav fairli provis owe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXwP3cEN2BVS",
        "colab_type": "code",
        "colab": {},
        "outputId": "86dc832e-6fc9-49a1-e057-ec255eb7625b"
      },
      "source": [
        "import nltk\n",
        "sno = nltk.stem.SnowballStemmer('english')\n",
        "print(sno.stem('grows'),sno.stem('russian'),\n",
        "      sno.stem('leaves'),sno.stem('fairly'),sno.stem('provision'),sno.stem('owed') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grow russian leav fair provis owe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeixdyLe2BVW",
        "colab_type": "code",
        "colab": {},
        "outputId": "ddf3fdee-b772-4b56-ed05-640696e2ba64"
      },
      "source": [
        "print(\" \".join(sno.languages))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POPAfC3Z2BVb",
        "colab_type": "code",
        "colab": {},
        "outputId": "4b1c3f6b-9215-4a57-a6e7-9515a05fe93d"
      },
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "st = LancasterStemmer()\n",
        "print(st.stem('grows'),st.stem('leaves'),st.stem('fairly'), st.stem('provision'),st.stem('owed') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grow leav fair provid ow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK2Cogt_2BVf",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2184cee-338f-4388-f138-29be14cf1570"
      },
      "source": [
        "st_pre = LancasterStemmer(strip_prefix_flag=True)\n",
        "st_pre.stem('kilometer') # Test Prefix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kilomet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDckeQbM2BVl",
        "colab_type": "code",
        "colab": {},
        "outputId": "48b0bd56-5ceb-4eea-b0bd-32abf3afc9d6"
      },
      "source": [
        "from nltk.stem.snowball import RussianStemmer\n",
        "\n",
        "stemmer = RussianStemmer()\n",
        "stemmer.stem('обучающиеся')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'обуча'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQRacFFY2BVp",
        "colab_type": "text"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEeYyCQ22BVq",
        "colab_type": "code",
        "colab": {},
        "outputId": "13dfe56e-1352-46a7-9aa7-073e38b00cfb"
      },
      "source": [
        "import nltk\n",
        "lemma = nltk.wordnet.WordNetLemmatizer()\n",
        "print(lemma.lemmatize('article'),lemma.lemmatize('leaves'),lemma.lemmatize('fairly'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "article leaf fairly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRoNDCdQ2BVu",
        "colab_type": "code",
        "colab": {},
        "outputId": "b8d0924f-802f-48dc-a5e5-adcf6bfa585d"
      },
      "source": [
        "print(lemma.lemmatize('grows'),lemma.lemmatize('russian'),\n",
        "      lemma.lemmatize('leaves'),lemma.lemmatize('fairly'),lemma.lemmatize('provision'),lemma.lemmatize('owed'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grows russian leaf fairly provision owed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}