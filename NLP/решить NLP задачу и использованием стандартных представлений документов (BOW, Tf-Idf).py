# -*- coding: utf-8 -*-
"""ДЗ 8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pk09JJT9A9SfT5eR03yJ7QN77EpkzzYq

###Решить NLP задачу и использованием стандартных представлений документов (BOW, Tf-Idf).

Датасет: https://www.kaggle.com/c/stumbleupon
"""

import numpy as np
import pandas as pd
from google.colab import files
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.stats import kurtosis
from scipy.stats import skew
from scipy.stats import shapiro
from scipy.stats import normaltest
import seaborn as sns
import re
from nltk.stem import WordNetLemmatizer
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB,  GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_curve, precision_score, auc, roc_auc_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import Normalizer
from sklearn.pipeline import make_pipeline
nltk.download('all')

"""## Вспомогательные функции"""

## Просмотр данных
def prosmotr(data):
  pd.set_option('display.max_columns', 100) #Размеры таблицы
  pd.set_option('display.max_rows', 100)
  pd.set_option('precision', 2) #Регулируем количество знаков после запятой:
  print('~~~~Содержание данных~~~~\n', data.head())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Размеры данных~~~\n', data.shape)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Названия колонок~~~\n', data.columns)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Информация о данных~~~\n')
  print(data.info())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Наличие пропусков в данных~~~\n', data.isna().sum())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Количество типов в данных~~~')
  print(data.dtypes.value_counts())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  kateg = list(data.select_dtypes(include=['object']).columns) # Делаем список категориальных данных
  print('~~~Категориальные данные~~~~')
  print(kateg)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_float = list(data.select_dtypes(include=['float64'])) #Делаем список числовых данных float
  print('~~~Числове данные float~~~~')
  print(chislov_float)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_int = list(data.select_dtypes(include=['int64'])) #Делаем список числовых данных int
  print('~~~Числове данные int~~~~')
  print(chislov_int)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы int64)~~~\n', data.describe(include=['int64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы float64)~~~\n', data.describe(include=['float64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')

## Анализ данных
def analyze(data):
  num = data.columns
  for i in num:
    print(i.title())
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')
    print("mean : ", np.mean(data[i]))
    print("var  : ", np.var(data[i]))
    print("skew : ", skew(data[i]))
    print("kurt : ", kurtosis(data[i]))
    print("shapiro : ", shapiro(data[i]))
    print("normaltest : ", normaltest(data[i]))
    print('~~~~~~~~~~~~~~~~~~~~~~~~~')
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')

# метрика
def value_of_metrics(y_true, y_pred):
    print('Accuracy: ', accuracy_score(y_true, y_pred))
    print('Recall: ', recall_score(y_true, y_pred))
    print('Precision: ', precision_score(y_true, y_pred))  
    print('F1: ', f1_score(y_true, y_pred))
    print('Roc_AUC: ', roc_auc_score(y_true, y_pred))
    
    fpr, tpr, threshold = roc_curve(y_true, y_pred)
    roc_auc = auc(fpr, tpr)
    plt.title('My DataSet')
    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
    plt.legend(loc = 'lower right')
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.show()

def text_preprocess(text):    
    reg = re.compile('[^а-яА-Яa-zA-Z0-9]') #
    text = text.lower()
    text = reg.sub(' ', text)
    lemmatizer = WordNetLemmatizer()
    text_ =''
    for word in text.split():
        #text_.append(lemmatizer.lemmatize(word))
        text_ = text_+ ' ' + lemmatizer.lemmatize(word)
    return text_

"""## По алгоритмам"""

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV


def fit_model(model, X, y, parameters):  
  cross_validation = StratifiedKFold(n_splits=5)

  grid_search = GridSearchCV(model,
                              scoring='accuracy',
                              param_grid=parameters,
                              cv=cross_validation,
                              verbose=1
                            )

  grid_search.fit(X, y)
  parameters=grid_search.best_params_
  print('Best score: {}'.format(grid_search.best_score_))
  print('Best parameters: {}'.format(parameters))

  return grid_search

"""## BAYES"""

from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB, ComplementNB


def Bern(train, targets):
  parameter_grid = {
                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],
                 'binarize': [0.0, 0.2, 0.5],
                 'fit_prior': ['True', 'False']
                 }
  bernoulli = BernoulliNB()
  trained_bernoulli = fit_model(bernoulli, train, targets, parameter_grid)
  return trained_bernoulli

def Gaus(train, targets):
  gaussian_nb = GaussianNB()
  parameter_grid = {
                 'var_smoothing': [1e-09, 1e-10, 1e-11, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]
                 }
  trained_gaussian_nb = fit_model(gaussian_nb, train, targets, parameter_grid)
  return trained_gaussian_nb

def Multi_nb(train, targets):
  multi_nb = MultinomialNB()
  parameter_grid = {
                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],
                 'fit_prior': ['True', 'False']
                 }
  trained_multi_nb = fit_model(multi_nb, train, targets, parameter_grid)
  return trained_multi_nb

def Complement_nb(train, targets):
  complement_nb = ComplementNB()
  parameter_grid = {
                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],
                 'fit_prior': ['True', 'False'],
                 'norm': ['True', 'False']
                 }
  trained_complement_nb = fit_model(complement_nb, train, targets, parameter_grid)
  return trained_complement_nb

"""## Загрузка данных"""

file = files.upload()

data = pd.read_csv("train.tsv", sep ='\t')

data.head()

prosmotr(data)

data['boilerplate'].iloc[0]

dt=data[['boilerplate','label']]
dt.head()

dt['label'].value_counts()

dt.shape

dt['boilerplate'] = dt['boilerplate'].apply(text_preprocess)

dt['boilerplate'].head()

"""## Bag of WORDS"""

X = dt['boilerplate']
y = dt['label']
cv = CountVectorizer() # Bag of WORDS (BOW)
X = cv.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47)

X_train.shape

X_test.shape

"""## Алгоритмы"""

## BAYS
bern_train = Bern(X_train, y_train)

value_of_metrics(y_test,bern_train.predict(X_test))

## Multi
multu_train = Multi_nb(X_train, y_train)

value_of_metrics(y_test,multu_train.predict(X_test))

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

logit = LogisticRegression()
logit.fit(X_train, y_train)

value_of_metrics(y_test,logit.predict(X_test))

svm = LinearSVC()
svm.fit(X_train, y_train)

value_of_metrics(y_test,svm.predict(X_test))

"""## Tfid"""

X = dt['boilerplate']
y = dt['label']
cv = TfidfVectorizer()
X = cv.fit_transform(X)

X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.25, random_state=47)

"""## Алгоритмы"""

## BAYS
bern_train2 = Bern(X_train2, y_train2)

value_of_metrics(y_test2,bern_train2.predict(X_test2))

## Multi
multu_train2 = Multi_nb(X_train2, y_train2)

value_of_metrics(y_test2,multu_train2.predict(X_test))

logit2 = LogisticRegression()
logit2.fit(X_train2, y_train2)

value_of_metrics(y_test2,logit2.predict(X_test2))

svm2 = LinearSVC()
svm2.fit(X_train2, y_train2)

value_of_metrics(y_test2,svm2.predict(X_test2))