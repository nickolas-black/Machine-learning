{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Spam-filter",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyWtxrNgKIPO",
        "colab_type": "text"
      },
      "source": [
        "### Пример спам-фильтра"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6K-DLLTKIPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating word dictionary\n",
        "def make_Dictionary(train_dir):\n",
        "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]    \n",
        "    all_words = []       \n",
        "    for mail in emails:    \n",
        "        with open(mail) as m:\n",
        "            for i,line in enumerate(m):\n",
        "                if i == 2:  #Body of email is only 3rd line of text file\n",
        "                    words = line.split()\n",
        "                    all_words += words\n",
        "    dictionary = Counter(all_words)\n",
        "    \n",
        "    list_to_remove = list(dictionary.keys())\n",
        "    for item in list_to_remove:\n",
        "        if item.isalpha() == False: \n",
        "            del dictionary[item]\n",
        "        elif len(item) == 1:\n",
        "            del dictionary[item]\n",
        "    dictionary = dictionary.most_common(3000)\n",
        "    return dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB9zJQzdKIPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(mail_dir): \n",
        "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "    features_matrix = np.zeros((len(files),3000))\n",
        "    docID = 0;\n",
        "    for fil in files:\n",
        "        with open(fil) as fi:\n",
        "            for i,line in enumerate(fi):\n",
        "                if i == 2:\n",
        "                    words = line.split()\n",
        "                    for word in words:\n",
        "                            wordID = 0\n",
        "                            for i,d in enumerate(dictionary):\n",
        "                                if d[0] == word:\n",
        "                                    wordID = i\n",
        "                                    features_matrix[docID,wordID] = words.count(word)\n",
        "            docID = docID + 1     \n",
        "    return features_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HddpGy-CKIPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training the classifiers\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRhvW7lNKIPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary of words with its frequency\n",
        "train_dir = 'train-mails'\n",
        "dictionary = make_Dictionary(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB_jO1O1KIPd",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ecd513e-29b1-4537-c80b-3650ded285ba"
      },
      "source": [
        "type(dictionary[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph10bziJKIPh",
        "colab_type": "code",
        "colab": {},
        "outputId": "b7f38a52-19d0-4e7d-818e-838b4fd725b0"
      },
      "source": [
        "print(dictionary[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('order', 1414), ('address', 1293), ('report', 1216), ('mail', 1127), ('send', 1079)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHLacCnTKIPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare feature vectors per training mail and its labels\n",
        "y_train = np.zeros(702) # y_train\n",
        "y_train[351:701] = 1\n",
        "train_matrix = extract_features(train_dir)\n",
        "# Bag Of Words\n",
        "# I like machine learning\n",
        "\n",
        "#dictionary: \n",
        "#i - 1, like - 2, dog - 3, cat - 4, machine - 5, learning - 6\n",
        "# (I like machine learning) ----->>>>>>> (1,1,0,0,1,1)\n",
        "# (I like machine learning and i am too) ------->>>>> (2,1,0,0,1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7IpDUMzKIPn",
        "colab_type": "code",
        "colab": {},
        "outputId": "50462771-8ee8-4cc6-e81c-bb8a423137b3"
      },
      "source": [
        "print(type(train_matrix),train_matrix.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (702, 3000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qaZWu5iKIPq",
        "colab_type": "code",
        "colab": {},
        "outputId": "650300f6-d3ad-4020-d0bb-f5145b16350b"
      },
      "source": [
        "# Training SVM and Naive bayes classifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "n_neighbors = 10\n",
        "\n",
        "model1 = MultinomialNB()\n",
        "model2 = KNeighborsClassifier(n_neighbors)\n",
        "model1.fit(train_matrix,y_train)\n",
        "model2.fit(train_matrix,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWJ3HTBKIPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the unseen mails for Spam\n",
        "test_dir = 'test-mails'\n",
        "test_matrix = extract_features(test_dir)\n",
        "y_test = np.zeros(260)\n",
        "y_test[130:260] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXEe6vjFKIPv",
        "colab_type": "code",
        "colab": {},
        "outputId": "9350b560-8349-4e14-bc51-2ff2774d5e49"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "result1 = model1.predict(test_matrix)\n",
        "result2 = model2.predict(test_matrix)\n",
        "print(confusion_matrix(y_test,result1), accuracy_score(y_test,result1))\n",
        "print(confusion_matrix(y_test,result2), accuracy_score(y_test,result2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[86 44]\n",
            " [77 53]] 0.5346153846153846\n",
            "[[81 49]\n",
            " [85 45]] 0.4846153846153846\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}