# -*- coding: utf-8 -*-
"""ДЗ_7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jx7nZfCccGl9koyx5LjgRIFLWpo46cLH

### С помощью алгоритма PCA найти размерность пространства признаков до которой можно понизить исходное пространство без потери точности.

Датасет: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from scipy.stats import kurtosis
from scipy.stats import skew
from scipy.stats import shapiro
from scipy.stats import normaltest

"""## Вспомогательные функции"""

## Просмотр данных
def prosmotr(data):
  pd.set_option('display.max_columns', 100) #Размеры таблицы
  pd.set_option('display.max_rows', 100)
  pd.set_option('precision', 2) #Регулируем количество знаков после запятой:
  print('~~~~Содержание данных~~~~\n', data.head())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Размеры данных~~~\n', data.shape)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Названия колонок~~~\n', data.columns)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Информация о данных~~~\n')
  print(data.info())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Наличие пропусков в данных~~~\n', data.isna().sum())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Количество типов в данных~~~')
  print(data.dtypes.value_counts())
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  kateg = list(data.select_dtypes(include=['object']).columns) # Делаем список категориальных данных
  print('~~~Категориальные данные~~~~')
  print(kateg)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_float = list(data.select_dtypes(include=['float64'])) #Делаем список числовых данных float
  print('~~~Числове данные float~~~~')
  print(chislov_float)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  chislov_int = list(data.select_dtypes(include=['int64'])) #Делаем список числовых данных int
  print('~~~Числове данные int~~~~')
  print(chislov_int)
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы int64)~~~\n', data.describe(include=['int64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')
  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы float64)~~~\n', data.describe(include=['float64']))
  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')

## Анализ данных
def analyze(data):
  num = data.columns
  for i in num:
    print(i.title())
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')
    print("mean : ", np.mean(data[i]))
    print("var  : ", np.var(data[i]))
    print("skew : ", skew(data[i]))
    print("kurt : ", kurtosis(data[i]))
    print("shapiro : ", shapiro(data[i]))
    print("normaltest : ", normaltest(data[i]))
    print('~~~~~~~~~~~~~~~~~~~~~~~~~')
    print('~~~~~~~~~~~~~~~~~~~~~~~~~\n')

"""## Загружаем данные"""

file = files.upload()

df = pd.read_csv('winequality-red.csv')

df.head()

prosmotr(df)

analyze(df)

y =df['quality']
x = df.drop(['quality'], axis=1)

x.shape

from sklearn.manifold import TSNE
ts = TSNE(random_state=47)
x_ts = ts.fit_transform(x)
plt.figure(figsize=(15,12))
plt.scatter(x_ts[:, 0], x_ts[:, 1], c=y, edgecolor='none', alpha=0.4, s=47, cmap=plt.cm.get_cmap('RdYlBu', 9))
plt.title('t-SNE')

from sklearn import decomposition

# Прогоним встроенный в sklearn PCA
pca = decomposition.PCA()
x_centered = x - x.mean(axis=0)
pca.fit(x_centered)

np.cumsum(pca.explained_variance_ratio_)

n=1
pca = decomposition.PCA(n_components=n)
pcar = pca.fit_transform(x)
print('Основных фич:',n,'Точность:{}'.format(np.sum(pca.explained_variance_ratio_)))
print('Размерность пространства признаков до которой можно понизить исходное пространство почти без потери точности =', n)

"""##  95 процентов это приемлимая точность и значит можно спроецировать на одну компонету"""

from sklearn.manifold import TSNE
tsne = TSNE(random_state=17)

X_tsne = tsne.fit_transform(pcar)

plt.figure(figsize=(12,10))
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, 
            edgecolor='red', alpha=0.7, s=40,
            cmap=plt.cm.get_cmap('nipy_spectral', 10))
plt.colorbar()
plt.title('WINE. t-SNE-pca projection')

X=pd.DataFrame(pcar, columns = ['pca_best_vector'])

from sklearn import metrics
from sklearn import datasets
import pandas as pd
from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering,DBSCAN

XX=pd.DataFrame(pcar, columns = ['pca_best_vector']) 
XXX=x
yy=y
X=XX

"""## K-means"""

for n in  [5,6,7,8,9]:
  al = KMeans(n_clusters=n, random_state=47)
  al.fit(X)
  print( n, metrics.silhouette_score(X, al.labels_))

"""## AgglomerativeClustering"""

for n in  [5,6,7,8,9]:
  al = AgglomerativeClustering(n_clusters=n)
  al.fit(X)
  print(n,metrics.silhouette_score(X, al.labels_))

X=XXX

"""## K-means 2"""

for n in  [5,6,7,8,9]:
  algo = KMeans(n_clusters=n, random_state=1)
  algo.fit(X)
  print(n,metrics.silhouette_score(X, algo.labels_))

"""## AgglomerativeClustering 2"""

for n in  [5,6,7,8,9]:
  algo = AgglomerativeClustering(n_clusters=n)
  algo.fit(X)
  print(n,metrics.silhouette_score(X, algo.labels_))

"""## до которой можно понизить исходное пространство без потери точности около 5-6"""