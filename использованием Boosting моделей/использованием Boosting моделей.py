# -*- coding: utf-8 -*-
"""ML_H_T_6_[WINE_QUALITY].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s9ti5bYQHZVwi7471lXf3pft-B9bDSax

### решить задачу классификации на предложенном датасете с использованием Boosting моделей.
Датасет: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

# IMPORTS
"""

import pandas as pd
from os import path

import xgboost as xgb
from xgboost.sklearn import XGBClassifier, XGBRegressor

from sklearn import metrics
from sklearn.model_selection import cross_val_score,  train_test_split

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV

"""# MOUNT DRIVE"""

# Mount gdrive
from google.colab import drive
drive.mount('/content/gdrive')

ROOT_PATH = f"/content/gdrive/My Drive/temp/"

#Loading dataset
filename = "winequality-red.csv"
wine = pd.read_csv(path.join(ROOT_PATH, filename))

wine.head()

wine['quality'].value_counts()

wine.isnull().sum()

"""We have no gapes.

# PREPROCESSING
"""

X = wine.drop(["quality"], axis=1)
y = wine["quality"]

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X)

X_scaled = scaler.fit_transform(X)

X_scaled.shape

X_scaled[10:20,:]

"""# train/test split"""

train_test_split?

from sklearn.model_selection import train_test_split

# TODO: сдлелать stratify после upsampling'а
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42784)

"""# models"""

def fit_model(model, X, y, X_test, y_test, parameters, scoring="accuracy"):  
  cross_validation = StratifiedKFold(n_splits=5)

  grid_search = GridSearchCV(model,
                              scoring=scoring,
                              param_grid=parameters,
                              cv=cross_validation,
                              verbose=1
                            )

  grid_search.fit(X, y)
  parameters=grid_search.best_params_
  print('Best score: {}'.format(grid_search.best_score_))
  print('Best parameters: {}'.format(parameters))

  return grid_search

"""## XGBClassifier"""

XGBClassifier?

"""```
Init signature: XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)
Docstring:     
Implementation of the scikit-learn API for XGBoost classification.

Parameters
----------
max_depth : int
    Maximum tree depth for base learners.
learning_rate : float
    Boosting learning rate (xgb's "eta")
n_estimators : int
    Number of trees to fit.
verbosity : int
    The degree of verbosity. Valid values are 0 (silent) - 3 (debug).
silent : boolean
    Whether to print messages while running boosting. Deprecated. Use verbosity instead.
objective : string or callable
    Specify the learning task and the corresponding learning objective or
    a custom objective function to be used (see note below).
booster: string
    Specify which booster to use: gbtree, gblinear or dart.
nthread : int
    Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)
n_jobs : int
    Number of parallel threads used to run xgboost.  (replaces ``nthread``)
gamma : float
    Minimum loss reduction required to make a further partition on a leaf node of the tree.
min_child_weight : int
    Minimum sum of instance weight(hessian) needed in a child.
max_delta_step : int
    Maximum delta step we allow each tree's weight estimation to be.
subsample : float
    Subsample ratio of the training instance.
colsample_bytree : float
    Subsample ratio of columns when constructing each tree.
colsample_bylevel : float
    Subsample ratio of columns for each level.
colsample_bynode : float
    Subsample ratio of columns for each split.
reg_alpha : float (xgb's alpha)
    L1 regularization term on weights
reg_lambda : float (xgb's lambda)
    L2 regularization term on weights
scale_pos_weight : float
    Balancing of positive and negative weights.
base_score:
    The initial prediction score of all instances, global bias.
seed : int
    Random number seed.  (Deprecated, please use random_state)
random_state : int
    Random number seed.  (replaces seed)
missing : float, optional
    Value in the data which needs to be present as a missing value. If
    None, defaults to np.nan.
importance_type: string, default "gain"
    The feature importance type for the feature_importances_ property: either "gain",
    "weight", "cover", "total_gain" or "total_cover".
\*\*kwargs : dict, optional
    Keyword arguments for XGBoost Booster object.  Full documentation of parameters can
    be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.
    Attempting to set a parameter via the constructor args and \*\*kwargs dict simultaneously
    will result in a TypeError.

    .. note:: \*\*kwargs unsupported by scikit-learn

        \*\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters
        passed via this argument will interact properly with scikit-learn.

Note
----
A custom objective function can be provided for the ``objective``
parameter. In this case, it should have the signature
``objective(y_true, y_pred) -> grad, hess``:

y_true: array_like of shape [n_samples]
    The target values
y_pred: array_like of shape [n_samples]
    The predicted values

grad: array_like of shape [n_samples]
    The value of the gradient for each sample point.
hess: array_like of shape [n_samples]
    The value of the second derivative for each sample point
File:           /usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py
Type:           type
```
"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

label_encoder.fit(y)

y_train_labeled = label_encoder.transform(y_train)
y_test_labeled = label_encoder.transform(y_test)

xgb1 = XGBClassifier(
        learning_rate =0.1,
        n_estimators=2,
        max_depth=5,
        min_child_weight=1,
        gamma=0,
        subsample=0.8,
        colsample_bytree=0.8,
        objective= 'multi:softmax',
        nthread=4,
        scale_pos_weight=1,
        seed=27)

cv_parameters = {
  "n_estimators": [2,3,5,10,20],
  "max_depth": range(2,10+1),
  'gamma': [i/10.0 for i in range(0,5)]
}

trained = fit_model(xgb1, X_train, y_train_labeled, X_test, y_test_labeled, parameters=cv_parameters, scoring="accuracy")

#Predict training set:
dtrain_predictions = trained.predict(X_train)
dtrain_predprob = trained.predict_proba(X_train)[:,1]
    
#Print model report:
print ("\nModel Report")
print ("Accuracy (Train): %.4g" % metrics.accuracy_score(y_train_labeled, dtrain_predictions))
# print ("AUC Score (Train): %f" % metrics.roc_auc_score(y_train_labeled, dtrain_predprob))

# Predict on testing data:
dtest_predictions = trained.predict(X_test)
dtest_predprob = trained.predict_proba(X_test)[:,1]
print ("Accuracy (Test): %.4g" % metrics.accuracy_score(y_test_labeled, dtest_predictions))
#print ('AUC Score (Test): %f' % metrics.roc_auc_score(y_test_labeled, dtest_predprob))