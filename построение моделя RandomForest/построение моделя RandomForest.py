# -*- coding: utf-8 -*-
"""Homework_5_керим.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ozmHMxwn5DEC4AOYfCoMoIASPNkCOQdJ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import numpy as np
import pandas as pd
from sklearn.preprocessing import PowerTransformer
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn import svm
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,auc, f1_score, confusion_matrix,precision_score, recall_score, roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""https://www.kaggle.com/becksddf/churn-in-telecoms-dataset"""

df = pd.read_csv('/content/drive/My Drive/ML/Homework_3/telecom_churn.csv')

df.head()

"""### Функция препроцессинга датафрейма"""

def transform_df(df):
  
  
  # True|False --> 1|0 && Yes|No --> 1|0
  df['Churn'] = df['Churn'].astype('int64') 
  df['International plan'] = df['International plan'].map({'Yes':1, 'No':0})
  df['Voice mail plan'] = df['Voice mail plan'].map({'Yes':1, 'No':0})
  
  # OneHotEncoding
  state_dummies = pd.get_dummies(df['State'], prefix = 'State')
  area_code_dummies = pd.get_dummies(df['Area code'], prefix='Area_code')
  df = pd.concat([df, state_dummies, area_code_dummies], axis=1)  
  df.drop(columns = ['State', 'Area code'], inplace=True) 
  
  
  # Нормировка
  columns_to_norm = [i for i in df.columns if 'Total' in i] + ['Number vmail messages'] + ['Account length'] + ['Customer service calls']
  for column in columns_to_norm:
    df[column] = df[column].apply(lambda x: x/df[column].mean())
    
  # Нормализация   
  yeo = PowerTransformer(method='yeo-johnson', standardize=False)
  for column in columns_to_norm:
    df[column] = yeo.fit_transform(df[column].values.reshape(df.shape[0],-1))
    
    
  columns_categorical = [i for i in df.columns if 'Area' in i or 'State' in i] + ['International plan'] + ['Voice mail plan']
  for column in columns_categorical:
    df[column] = yeo.fit_transform(df[column].values.reshape(df.shape[0],-1))
    
  
  return df

"""### Преобразуем датафрейм"""

df = transform_df(df)

"""### Стандартизация"""

cols_to_stand = [i for i in df.columns if i!='Churn']
scaler = MinMaxScaler()
scaler.fit(df[cols_to_stand])
df[cols_to_stand] = scaler.transform(df[cols_to_stand])

def unpack_X_and_y(df, answers_col):
  return df.drop([answers_col],  axis=1), df[answers_col]

"""### Находим лучшие фичи и избавляемся от всех, кто не попал в топ"""

def select_best_features(X, y):
  #apply SelectKBest class to extract top 10 best features
  bestfeatures = SelectKBest(score_func=chi2, k=10)
  fit = bestfeatures.fit(X,y)
  dfscores = pd.DataFrame(fit.scores_)
  dfcolumns = pd.DataFrame(X.columns)
  #concat two dataframes for better visualization 
  featureScores = pd.concat([dfcolumns,dfscores],axis=1)
  featureScores.columns = ['Specs','Score']  #naming the dataframe columns
  return list(featureScores.nlargest(10,'Score')['Specs'])   #print 10 best features

best_features = select_best_features(*unpack_X_and_y(df, 'Churn'))

df = pd.concat([df[best_features], df['Churn']],axis=1)

df.head()

"""### Делим датафрейм на X и y"""

X, y = unpack_X_and_y(df, 'Churn')

"""### Функция для вывода оценки по разным метрикам"""

def value_of_metrics(y_true, y_pred):
    print('Accuracy: ', accuracy_score(y_true, y_pred))
    print('Recall: ', recall_score(y_true, y_pred))
    print('Precision: ', precision_score(y_true, y_pred))  
    print('F1: ', f1_score(y_true, y_pred))
    print('Roc_AUC: ', roc_auc_score(y_true, y_pred))
    print('Confusion Matrix: ')
    print(pd.DataFrame(confusion_matrix(y_true, y_pred)))
    
    fpr, tpr, threshold = roc_curve(y_true, y_pred)
    roc_auc = auc(fpr, tpr)
    plt.title('My DataSet')
    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
    plt.legend(loc = 'lower right')
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.show()

"""### Используем метод GridSearch для определения лучших параметров RandomForest по метрике Recall."""

def get_grid_RFC(X, y, n_estimators, max_depth, scoring='recall', cv=5):
  grid_param = {
      'n_estimators': n_estimators,
      'max_depth': max_depth
  }
  
  classifier = RandomForestClassifier()
  
  grid = GridSearchCV(estimator=classifier,
                         param_grid=grid_param,
                         scoring=scoring,
                         cv=cv,
                         n_jobs=-1)
  
  grid.fit(X, y)
  
  return grid

"""### Разделим датасет на тренировочную и тестовую выборки"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)

grid_RFC_1 = get_grid_RFC(X_train, y_train, np.linspace(3, 50, 20, dtype=int), np.linspace(2, 15, 5, dtype=int))

value_of_metrics(y_test, grid_RFC_1.predict(X_test))

"""### Используем техники изменения объемов выборок

#### Добавляем копии объеков миноритарного класса
"""

not_churn = df[df.Churn==0]
churn = df[df.Churn==1]

churn_upsampled = resample(churn,
                          replace=True,
                          n_samples=len(not_churn), 
                          random_state=27)


upsampled = pd.concat([not_churn, churn_upsampled])

upsampled.Churn.value_counts()

y_train_new = upsampled.Churn
X_train_new = upsampled.drop('Churn', axis=1)

grid_RFC_2 = get_grid_RFC(X_train_new, y_train_new, np.linspace(3, 50, 20, dtype=int), np.linspace(2, 15, 5, dtype=int))

value_of_metrics(y_test, grid_RFC_2.predict(X_test))

"""#### Уменьшаем количество объектов мажоритарного класс"""

not_churn_downsampled = resample(not_churn,
                                replace = False, 
                                n_samples = len(churn), 
                                random_state = 27)
downsampled = pd.concat([not_churn_downsampled, churn])
downsampled.Churn.value_counts()

y_train_new_new = downsampled.Churn
X_train_new_new = downsampled.drop('Churn', axis=1)

grid_RFC_3 = get_grid_RFC(X_train_new_new, y_train_new_new, np.linspace(3, 50, 20, dtype=int), np.linspace(2, 15, 5, dtype=int))

value_of_metrics(y_test, grid_RFC_3.predict(X_test))

"""#### Синтетическое увеличение миноритарного класса"""

sm = SMOTE(random_state=27, ratio=1.0)
X_train_new_new_new, y_train_new_new_new = sm.fit_sample(X_train, y_train)

grid_RFC_4 = get_grid_RFC(X_train_new_new_new, y_train_new_new_new, np.linspace(3, 50, 20, dtype=int), np.linspace(2, 15, 5, dtype=int))

value_of_metrics(y_test, grid_RFC_4.predict(X_test))