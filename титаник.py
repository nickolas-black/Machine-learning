# -*- coding: utf-8 -*-
"""Титаник.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZPNjy30tTvDL2PbO7SB0HvN2HO0cLZgD

## Соревнования по Титаник на Kaggle
Пример кода для отправки решения в соревновании Kaggle - https://www.kaggle.com/c/titanic/data
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from google.colab import files
# %matplotlib inline

"""## Устанавливаем Kaggle API"""

!pip install kaggle

"""Загружаем токен аутентификации"""

file = files.upload()

!ls

!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle

"""# Загружаем данные с сайта Kaggle"""

!kaggle competitions download -c titanic

!ls

"""## Проверяем данные"""

!head train.csv

!head test.csv

!head gender_submission.csv

"""## Подготовка данных для обучения сети"""

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

print(train.isna().sum())
print(test.isna().sum())

print(train.corr())

train['Embarked'] = train['Embarked'].fillna('S')
train['Family_size'] = train['SibSp']+train['Parch']+1
train['Fare_class'] = pd.qcut(train.Fare, 5, labels=False)

test['Fare'] = test['Fare'].fillna(test.Fare.mean())
test['Family_size'] = test['SibSp']+test['Parch']+1
test['Fare_class'] = pd.qcut(test.Fare, 5, labels=False)

print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))

print(train[["Sex", "Survived"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))

print(train[["SibSp", "Survived"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))

print(train[["Parch", "Survived"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))

print(train[["Family_size", "Survived"]].groupby(['Family_size'], as_index=False).mean().sort_values(by='Survived', ascending=False))

print(train[["Fare_class", "Survived"]].groupby(['Fare_class'], as_index=False).mean().sort_values(by='Survived', ascending=False))

f, axes = plt.subplots(4, 3, figsize=(15, 15))
sns.catplot('Pclass',data=train,kind='count',ax=axes[0,0]) #Number of people per ticket class
sns.catplot('Sex',data=train,hue='Pclass',kind='count',ax=axes[0,1]) #Number of people per sex, further divided per ticket class
sns.catplot('Family_size',data=train,hue='Pclass',kind='count',ax=axes[0,2]) #Number of people per family size, further divided per ticket class
sns.catplot('Family_size',data=train,hue='Sex',kind='count',ax=axes[1,0]) #Number of people per family size, further divided per sex
sns.catplot('Fare_class',data=train,hue='Pclass',kind='count',ax=axes[1,1]) #Number of people per fare class, further divided per ticket class
sns.catplot('Fare_class',data=train,hue='Sex',kind='count',ax=axes[1,2]) #Number of people per fare class, further divided per sex
sns.catplot(x='Pclass',y='Survived',data=train,kind='bar',ci=None,ax=axes[2,0]) #Number of survived people per ticket class
sns.catplot(x='Sex',y='Survived',data=train,hue='Pclass',kind='bar',ci=None,ax=axes[2,1]) #Number of survived people per sex, further divided per ticket class
sns.catplot(x='Family_size',y='Survived',data=train,hue='Pclass',kind='bar',ci=None,ax=axes[2,2]) #Number of survived people per family size, further divided per ticket class
sns.catplot(x='Family_size',y='Survived',data=train,hue='Sex',kind='bar',ci=None,ax=axes[3,0]) #Number of survived people per family size, further divided per sex
sns.catplot(x='Fare_class',y='Survived',data=train,hue='Pclass',kind='bar',ci=None,ax=axes[3,1]) #Number of survived people per fare class, further divided per ticket class
sns.catplot(x='Fare_class',y='Survived',data=train,hue='Sex',kind='bar',ci=None,ax=axes[3,2]) #Number of survived people per fare class, further divided per sex
for abc in range(2,14,1):
    plt.close(abc)

# Converting sex and embarked to dummy variables
sex_type = {"male":0,"female":1}
train["Sex"] = train["Sex"].map(sex_type)
test["Sex"] = test["Sex"].map(sex_type)
embarked_loc = {"S":0,"C":1,"Q":2}
train["Embarked"] = train["Embarked"].map(embarked_loc)
test["Embarked"] = test["Embarked"].map(embarked_loc)

"""подготавливаем данные обучения"""

X_train = train.drop(["Survived","Fare","Cabin","Age","PassengerId","Name","Ticket"], axis=1)
Y_train = train["Survived"]
X_test = test.drop(["PassengerId","Name","Age","Ticket","Fare","Cabin"],axis=1)

"""# Обучаем"""

random_forest = RandomForestClassifier(n_estimators=50)
random_forest.fit(X_train, Y_train)

Y_prediction = random_forest.predict(X_test)

random_forest.score(X_train, Y_train)

f, axes = plt.subplots(1, 2, figsize=(10, 5))
sns.distplot(train["Age"],hist=True,bins=20,ax=axes[0]) #approximately normal distribution, it can be used to fill the NaNs
axes[0].set_title('Age distribution train set')
ax2 = sns.distplot(test["Age"],hist=True,bins=20,ax=axes[1], color="r") #approximately normal distribution, it can be used to fill the NaNs
axes[1].set_title('Age distribution test set')

# Filling the Age NaNs by sampling from the two normal distributions
meanAge_train, stdAge_train = train["Age"].mean(), train["Age"].std() #mean and standard deviation for the column Age, train set
nullAge_train = train["Age"].isnull() #get the indeces where NaNs are present in the Age column
sampAge_norm_dist_train = np.random.normal(meanAge_train, stdAge_train, nullAge_train.sum())
for ii in range(0,len(sampAge_norm_dist_train)): #checking for eventual age values below zero
    if sampAge_norm_dist_train[ii] < 0:
        sampAge_norm_dist_train[ii] = np.random.normal(meanAge_train, stdAge_train, 1)
train["Age"].loc[nullAge_train] = sampAge_norm_dist_train #fill in the NaNs with the samples values
        

meanAge_test, stdAge_test = test["Age"].mean(), test["Age"].std() #same procedure as for the train set
nullAge_test = test["Age"].isnull()
sampAge_norm_dist_test = np.random.normal(meanAge_test, stdAge_test, nullAge_test.sum())
for jj in range(0,len(sampAge_norm_dist_test)):
    if sampAge_norm_dist_test[jj] < 0:
        sampAge_norm_dist_test[jj] = np.random.normal(meanAge_test, stdAge_test, 1)
test["Age"].loc[nullAge_test] = sampAge_norm_dist_test

# Now both train and test set should have no NaNs in the Age column
print(train.isna().sum()) 
print(test.isna().sum())

# Plotting Age distribution after NaNs filling
f, axes = plt.subplots(1, 2, figsize=(10, 5))
sns.distplot(train["Age"],hist=True,bins=20,ax=axes[0]) #approximately normal distribution, it can be used to fill the NaNs
axes[0].set_title('Age distribution train set after NaNs filling')
ax2 = sns.distplot(test["Age"],hist=True,bins=20,ax=axes[1], color="r") #approximately normal distribution, it can be used to fill the NaNs
axes[1].set_title('Age distribution test set after NaNs filling')

# Binning Age into discrete intervals
age_threshold = [0,18,35,50,65,train["Age"].max()] #should make sense to divide into minors, young adults, adults, old adults, elderly
age_label = [1,2,3,4,5] #new label for the age bins
train["Age_discrete"] = pd.cut(train["Age"], age_threshold, labels=age_label, include_lowest = True) #new column that will be used in the classification
test["Age_discrete"] = pd.cut(test["Age"], age_threshold, labels=age_label, include_lowest = True) #same procedure for the test dataset

# Creating input train and test structures with Age
X_train_w_age = train.drop(["Survived","Fare","Cabin","Age","PassengerId","Name","Ticket"], axis=1)
X_test_w_age = test.drop(["PassengerId","Name","Age","Ticket","Fare","Cabin"],axis=1)

# Random forest algorigthm with 100 estimations, including Age as variable
random_forest_w_age = RandomForestClassifier(n_estimators=100)
random_forest_w_age.fit(X_train_w_age, Y_train)

Y_prediction_w_age = random_forest_w_age.predict(X_test_w_age)

random_forest_w_age.score(X_train_w_age, Y_train)

# Calculating the importance of each variable in both models
features= X_train.columns
importances = random_forest.feature_importances_
indices = np.argsort(importances)
plt.figure(1)
plt.title('Feature Importances without Age')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')

features_w_age = X_train_w_age.columns
importances_w_age = random_forest_w_age.feature_importances_
indices_w_age = np.argsort(importances_w_age)
plt.figure(1)
plt.title('Feature Importances with Age')
plt.barh(range(len(indices_w_age)), importances_w_age[indices_w_age], color='b', align='center')
plt.yticks(range(len(indices_w_age)), [features_w_age[i] for i in indices_w_age])
plt.xlabel('Relative Importance')

"""## сохраняем результат"""

submission_titanic = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':Y_prediction_w_age})
submission_titanic.to_csv("titanic-submission.csv", index=False)

submission_titanic_without_age = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':Y_prediction})
submission_titanic_without_age.to_csv('Titanic_submission_2.csv',index=False)

from google.colab import files
files.download("Titanic_submission_2.csv")

"""## Отправка результата"""

!kaggle competitions submit -c titanic -m "Submition from Colab" -f titanic-submission.csv

!kaggle competitions submit -c titanic -m "Submition from Colab" -f Titanic_submission_2.csv