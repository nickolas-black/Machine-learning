# -*- coding: utf-8 -*-
"""churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M2hv_t-QvS_RPzpnAYyJikwR5TyCfGVg

### Предобработка признаков датасета как числовых, так и категориальных. Далее выполнить нормировку признаков с помощью библиотеки scikit learn (StandartScalar) и обучить известные Вам модели бинарной классификации (kNN, Bayes, SVM).
"""

import numpy as np
import pandas as pd

"""https://www.kaggle.com/becksddf/churn-in-telecoms-dataset

### Чтение из файла и первичный анализ
"""

df = pd.read_csv('telecom_churn.csv')

df.head()

"""По умолчанию `Pandas` выводит всего 20 столбцов и 60 строк. Можно использовать функцию `set_option`:"""

pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)

"""Регулируем количество знаков после запятой:"""

pd.set_option('precision', 2)

"""**Посмотрим на размер данных, названия признаков и их типы**"""

print(df.shape)

print(df.columns)

print(df.info())

"""**Изменить тип колонки** можно с помощью метода `astype`. Применим этот метод к признаку `Churn` и переведём его в `int64`:"""

df['Churn'] = df['Churn'].astype('int64')

"""Метод **`describe`** показывает основные статистические характеристики данных по каждому числовому признаку (типы `int64` и `float64`): число непропущенных значений, среднее, стандартное отклонение, диапазон, медиану, 0.25 и 0.75 квартили."""

df.describe()

"""Чтобы посмотреть статистику по нечисловым признакам, нужно явно указать интересующие нас типы в параметре `include`. Можно также задать `include`='all', чтоб вывести статистику по всем имеющимся признакам."""

df.describe(include=['object', 'bool'])

"""Для категориальных (тип `object`) и булевых (тип `bool`) признаков  можно воспользоваться методом **`value_counts`**. Посмотрим на распределение нашей целевой переменной — `Churn`:"""

df['Churn'].value_counts()

"""2850 пользователей из 3333 — лояльные, значение переменной `Churn` у них — `0`.

Посмотрим на распределение пользователей по переменной `Area code`. Укажем значение параметра `normalize=True`, чтобы посмотреть не абсолютные частоты, а относительные.
"""

df['Area code'].value_counts(normalize=True)

"""### Сортировка

`DataFrame` можно отсортировать по значению какого-нибудь из признаков. В нашем случае, например, по `Total day charge` (`ascending=False` для сортировки по убыванию):
"""

df.sort_values(by='Total day charge', 
        ascending=False).head()

"""Сортировать можно и по группе столбцов:"""

df.sort_values(by=['Churn', 'Total day charge'],
        ascending=[True, False]).head()

"""### Индексация и извлечение данных

`DataFrame` можно индексировать по-разному. В связи с этим рассмотрим различные способы индексации и извлечения нужных нам данных из датафрейма на примере простых вопросов.

Для извлечения отдельного столбца можно использовать конструкцию вида `DataFrame['Name']`. Воспользуемся этим для ответа на вопрос: **какова доля нелояльных пользователей в нашем датафрейме?**
"""

df['Churn'].mean()

"""14,5% — довольно плохой показатель для компании.

Очень удобной является логическая индексация `DataFrame` по одному столбцу. Выглядит она следующим образом: `df[P(df['Name'])]`, где `P` - это некоторое логическое условие, проверяемое для каждого элемента столбца `Name`. Итогом такой индексации является `DataFrame`, состоящий только из строк, удовлетворяющих условию `P` по столбцу `Name`. 

Воспользуемся этим для ответа на вопрос: **каковы средние значения числовых признаков среди нелояльных пользователей?**
"""

df[df['Churn'] == 1].mean()

"""Скомбинировав предыдущие два вида индексации, ответим на вопрос: **сколько в среднем в течение дня разговаривают по телефону нелояльные пользователи**?"""

df[df['Churn'] == 1]['Total day minutes'].mean()

"""**Какова максимальная длина международных звонков среди лояльных пользователей (`Churn == 0`), не пользующихся услугой международного роуминга (`'International plan' == 'No'`)?**"""

df[(df['Churn'] == 0) & (df['International plan'] == 'No')]['Total intl minutes'].max()

"""Датафреймы можно индексировать как по названию столбца или строки, так и по порядковому номеру. Для индексации **по названию** используется метод **`loc`**, **по номеру** — **`iloc`**.

В первом случае мы говорим _«передай нам значения для id строк от 0 до 5 и для столбцов от State до Area code»_, а во втором — _«передай нам значения первых пяти строк в первых трёх столбцах»_. 

В случае `iloc` срез работает как обычно, однако в случае `loc` учитываются и начало, и конец среза. Да, неудобно, да, вызывает путаницу.
"""

df.loc[0:5, 'State':'Area code']

df.iloc[0:5, 0:3]

"""Метод `ix` индексирует и по названию, и по номеру, но он вызывает путаницу, и поэтому был объявлен устаревшим (deprecated).

Если нам нужна первая или последняя строчка датафрейма, пользуемся конструкцией `df[:1]` или `df[-1:]`:
"""

df[-1:]

"""### Применение функций: `apply`, `map` и др.

**Применение функции к каждому столбцу:**
"""

df.apply(np.max)

"""Метод `apply` можно использовать и для того, чтобы применить функцию к каждой строке. Для этого нужно указать `axis=1`.

**Применение функции к каждой ячейке столбца**

Допустим, по какой-то причине нас интересуют все люди из штатов, названия которых начинаются на 'W'. В данному случае это можно сделать по-разному, но наибольшую свободу дает связка `apply`-`lambda` – применение функции ко всем значениям в столбце.
"""

df[df['State'].apply(lambda state: state[0] == 'W')].head()

"""Метод `map` можно использовать и для **замены значений в колонке**, передав ему в качестве аргумента словарь вида `{old_value: new_value}`:"""

d = {'No' : False, 'Yes' : True}
df['International plan'] = df['International plan'].map(d)
df.head()

"""Аналогичную операцию можно провернуть с помощью метода `replace`:"""

df = df.replace({'Voice mail plan': d})
df.head()

"""### Группировка данных

В общем случае группировка данных в Pandas выглядит следующим образом:

```
df.groupby(by=grouping_columns)[columns_to_show].function()
```

1. К датафрейму применяется метод **`groupby`**, который разделяет данные по `grouping_columns` – признаку или набору признаков.
3. Индексируем по нужным нам столбцам (`columns_to_show`). 
2. К полученным группам применяется функция или несколько функций.

**Группирование данных в зависимости от значения признака `Churn` и вывод статистик по трём столбцам в каждой группе.**
"""

columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']

df.groupby(['Churn'])[columns_to_show].describe(percentiles=[])

"""Сделаем то же самое, но немного по-другому, передав в `agg` список функций:"""

columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']

df.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, np.max])